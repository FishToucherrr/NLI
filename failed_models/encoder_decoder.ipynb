{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fudan PRML22 Spring Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your name and Student ID: [Name], [Student ID]*\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet, and a .pdf report file) with your assignment submission.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations, you have come to the last challenge!**\n",
    "\n",
    "Having finished the past two assignments, we think all you gugs already have a solid foundation in the field of machine learning and deep learning. And now you are qualified to apply machine learning algorithms to the real-world tasks you are interested in, or start your machine learning research. \n",
    "\n",
    "**In this final project, you are free to choose a topic you are passionate about. The project can be an application one, a theoretical one or implementing your own amazing machine learning/deep learning framework like a toy pytorch. If you don't have any idea, we will also provide you with a default one you can play with.** \n",
    "\n",
    "**! Notice: If you want to work on your own idea, you have to email the TA (lip21[at]m.fudan.edu.cn) to give a simple project proposal first before May 22, 2022.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Project: Natural Language Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sherlock](./img/inference.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default final project this semester is a NLP task called \"Natural Language Inference\". Though deep neural networks have demonstrated astonishing performance in many tasks like text classification and generation, you might somehow think they are just \"advanced statistics\" but far from *intelligent* machines. One intelligent machine must be able to reason, you may think. And in this default final project, your aim is to design a machine which can conduct inference. The machine can know that \"A man inspects the uniform of a figure in some East Asian country\" is contradictory to \"The man is sleeping\", and \"a soccer game with multiple males playing.\" entails \"some men are playing a sport\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we use this time is the Original Chinese Natural Language Inference (OCNLI) dataset[1]. It is a chinese NLI dataset with about 50k training data and 3k development data. The sentence pairs in the dataset are labeled as \"entailment\", \"neutral\" and \"contradiction\". Due to they release the test data without its labels, we select 5k data pairs from the training data as labeled test data, and the other 45k data as your t. You can visit the [GitHub link](https://github.com/CLUEbenchmark/OCNLI) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you finished the NLI task with the full 50k training set, you have to complete an advanced challenge. You have to select **at most 5k data** from the training set as labeled training set, leaving the other training data as unlabeled training set, then use these labeled and unlabeled data to finish the same NLI task. You can randomly choosing the 5k training data but can also think up some ideas to select more **important data** as labeled training data. Like assignment1, you may have to think how to use the unlabeled training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the deep learning frameworks like paddle, pytorch, tensorflow in your experiment but not more high-level libraries like Huggingface. Please write down the version of them in the './requirements.txt' file.\n",
    "\n",
    "**! Notice: You CAN NOT use any other people's pretrained model like 'bert-base-chinese' in this default project. You are encouraged to design your own model and algorithm, no matter it looks naive or not.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLI is a traditional but promising NLP task, and you can search the Google/Bing for more information. Some key words can be \"natural language inference with attention\", \"training data selection\", \"semi-surpervised learning\", \"unsupervised representation learning\" and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "import the libraries and load the dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup code\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import jieba\n",
    "import time\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../dataset'\n",
    "\n",
    "train_data_file = dataset_path + '/train.json'\n",
    "dev_data_file = dataset_path + '/dev.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from  ../dataset/train.json\n",
      "there are  45437 sentence pairs in this file.\n",
      "loading data from  ../dataset/dev.json\n",
      "there are  2950 sentence pairs in this file.\n"
     ]
    }
   ],
   "source": [
    "def read_ocnli_file(data_file):\n",
    "    # read the ocnli file. feel free to change it. \n",
    "    print (\"loading data from \", data_file)\n",
    "    \n",
    "    text_outputs = []\n",
    "    label_outputs = []\n",
    "    \n",
    "    label_to_idx = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "    \n",
    "    with open(data_file, 'r', encoding=\"utf-8\") as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            line = json.loads(line.strip())\n",
    "            text_a, text_b, label = line['sentence1'], line['sentence2'],line['label']\n",
    "            label_id = label_to_idx[label.strip()]\n",
    "            \n",
    "            text_outputs.append((text_a,text_b))\n",
    "            label_outputs.append(label_id)\n",
    "\n",
    "            line = f.readline()\n",
    "                \n",
    "    print (\"there are \", len(label_outputs), \"sentence pairs in this file.\")\n",
    "    return text_outputs, label_outputs\n",
    "\n",
    "\n",
    "training_data, training_labels = read_ocnli_file(train_data_file)\n",
    "dev_data, dev_labels = read_ocnli_file(dev_data_file)\n",
    "\n",
    "stop_words=[]\n",
    "\n",
    "with open(\"../stop_words.txt\",'r',encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        stop_words.append(str(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data samples:  [('对,对,对,对,对,具体的答复.', '要的是抽象的答复'), ('当前国际形势仍处于复杂而深刻的变动之中', '一个月后将发生世界战争'), ('在全县率先推行宅基地有偿使用,全乡20年无须再扩大宅基地', '宅基地有偿使用获得较好成果,将在更大范围实施。'), ('上海马路上的喧声也是老调子', '上海有很多条马路'), ('那你看看第二封信什么时候到吧.', '第一封信已经收到了。')]\n",
      "training labels samples:  [2, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print (\"training data samples: \", training_data[:5])\n",
    "print (\"training labels samples: \", training_labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your may have to explore the dataset and do some analysis first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a unique index per word to use as the inputs and targets of\n",
    "the networks later. To keep track of all this we will use a helper class\n",
    "called ``Lang`` which has word → index (``word2index``) and index → word\n",
    "(``index2word``) dictionaries, as well as a count of each word\n",
    "``word2count`` which will be used to replace rare words later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['对对对对对具体的答复', '当前国际形势仍处于复杂而深刻的变动之中', '在全县率先推行宅基地有偿使用全乡年无须再扩大宅基地', '上海马路上的喧声也是老调子', '那你看看第二封信什么时候到吧']\n",
      "45437\n"
     ]
    }
   ],
   "source": [
    "training_premise = []\n",
    "training_hypothesis = []\n",
    "\n",
    "def is_chinese(uchar):\n",
    "    if uchar >= u'\\u4e00' and uchar <= u'\\u9fa5':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def format_str(content):\n",
    "    content_str = ''\n",
    "    for i in content:\n",
    "        if is_chinese(i):\n",
    "            content_str = content_str + i\n",
    "    return content_str\n",
    "\n",
    "for pair in training_data:\n",
    "    training_premise.append(format_str(pair[0]))\n",
    "    training_hypothesis.append(format_str(pair[1]))\n",
    "\n",
    "print(training_premise[:5])\n",
    "print(len(training_premise))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\use\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.641 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['对', '对', '对', '对', '对', '具体', '的', '答复'], ['当前', '国际形势', '仍', '处于', '复杂', '而', '深刻', '的', '变动', '之中'], ['在', '全县', '率先', '推行', '宅基地', '有偿', '使用', '全乡', '年', '无须再', '扩大', '宅基地'], ['上海', '马路上', '的', '喧声', '也', '是', '老调子'], ['那', '你', '看看', '第二', '封信', '什么', '时候', '到', '吧']]\n",
      "[['对', '对', '对', '对', '对', '具体', '答复'], ['当前', '国际形势', '仍', '处于', '复杂', '而', '深刻', '变动', '之中'], ['在', '全县', '率先', '推行', '宅基地', '有偿', '使用', '全乡', '年', '无须再', '扩大', '宅基地'], ['上海', '马路上', '喧声', '也', '是', '老调子'], ['那', '你', '看看', '第二', '封信', '什么', '时候', '到']]\n",
      "[['要', '是', '抽象', '答复'], ['一个月', '后', '将', '发生', '世界', '战争'], ['宅基地', '有偿', '使用', '获得', '较', '好', '成果', '将', '在', '更', '大', '范围', '实施'], ['上海', '有', '很多', '条', '马路'], ['第一', '封信', '已经', '收到']]\n"
     ]
    }
   ],
   "source": [
    "def split_words(datas):\n",
    "    cut_words = map(lambda s: list(jieba.cut(s)), datas)\n",
    "    return list(cut_words)\n",
    "\n",
    "training_premise = split_words(training_premise)\n",
    "training_hypothesis = split_words(training_hypothesis)\n",
    "\n",
    "print(training_premise[:5])\n",
    "\n",
    "def drop_stopwords(contents, stopwords):\n",
    "    contents_clean = []\n",
    "    for line in contents:\n",
    "        line_clean = []\n",
    "        for word in line:\n",
    "            if word in stopwords:\n",
    "                continue\n",
    "            line_clean.append(word)\n",
    "        contents_clean.append(line_clean)\n",
    "    return contents_clean\n",
    "\n",
    "training_premise = drop_stopwords(training_premise,stop_words)\n",
    "training_hypothesis = drop_stopwords(training_hypothesis,stop_words)\n",
    "\n",
    "print(training_premise[:5])\n",
    "print(training_hypothesis[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max 29\n",
      "Avg 11.471025815964962\n",
      "45437\n"
     ]
    }
   ],
   "source": [
    "Max = 0\n",
    "Sum = 0\n",
    "count = 0\n",
    "for sentence in training_premise:\n",
    "    count += 1\n",
    "    Max = max(Max,len(sentence))\n",
    "    Sum += len(sentence)\n",
    "print(\"Max\",Max)\n",
    "print(\"Avg\",Sum/count)\n",
    "print(len(training_premise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter the train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_list = []\n",
    "\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "for i in range(len(training_premise)):\n",
    "    if len(training_premise[i]) > MAX_LENGTH or len(training_hypothesis[i]) > MAX_LENGTH :\n",
    "        del_list.append(i)\n",
    "\n",
    "for idx in sorted(del_list, reverse = True):\n",
    "    del training_premise[idx]\n",
    "    del training_hypothesis[idx]\n",
    "    del training_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max 10\n",
      "Avg 7.008875999648475\n",
      "22758\n"
     ]
    }
   ],
   "source": [
    "Max = 0\n",
    "Sum = 0\n",
    "count = 0\n",
    "for sentence in training_premise:\n",
    "    count += 1\n",
    "    Max = max(Max,len(sentence))\n",
    "    Sum += len(sentence)\n",
    "print(\"Max\",Max)\n",
    "print(\"Avg\",Sum/count)\n",
    "print(len(training_premise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN 16185\n"
     ]
    }
   ],
   "source": [
    "Chinese = Lang(\"CN\")\n",
    "for sentence in training_premise:\n",
    "    Chinese.addSentence(sentence)\n",
    "for sentence in training_hypothesis:\n",
    "    Chinese.addSentence(sentence)\n",
    "\n",
    "print(Chinese.name, Chinese.n_words)\n",
    "\n",
    "premise_vec = []\n",
    "hypothesis_vec = []\n",
    "\n",
    "for sentence in training_premise:\n",
    "    word_list = []\n",
    "    for word in sentence:\n",
    "        word_list.append(Chinese.word2index[word])\n",
    "    premise_vec.append(word_list)\n",
    "\n",
    "for sentence in training_hypothesis:\n",
    "    word_list = []\n",
    "    for word in sentence:\n",
    "        word_list.append(Chinese.word2index[word])\n",
    "    hypothesis_vec.append(word_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methodology (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder of this network is a RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size,batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.shape[0]\n",
    "        embedded = self.embedding(input).view(batch_size, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size,batch_first=True)\n",
    "        # self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.out = nn.Linear(hidden_size, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.shape[0]\n",
    "        output = self.embedding(input).view(batch_size, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # output = self.softmax(self.out(output[0]))\n",
    "        output = self.out(output[0])\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, batch_first=True)\n",
    "        # self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.out = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        batch_size = input.shape[0]\n",
    "        embedded = self.embedding(input).view(batch_size, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_input = torch.cat((embedded, hidden.view(batch_size, 1, -1)), 2).view(batch_size, -1)\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(attn_input), dim=-1)\n",
    "\n",
    "        # attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "        #                          encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        attn_applied = torch.bmm(attn_weights.view(batch_size,1,-1), encoder_outputs)\n",
    "\n",
    "        # output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = torch.cat((embedded, attn_applied), 2)\n",
    "        output = self.attn_combine(output)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        # output = F.log_softmax(self.out(output), dim=-1)\n",
    "        output = self.out(output)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Soft(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Soft, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.l1 = nn.Linear(self.input_size,1000)\n",
    "        self.l2 = nn.Linear(1000,500)\n",
    "        self.l3 = nn.Linear(500,250)\n",
    "        self.l4 = nn.Linear(250,100)\n",
    "        self.l5 = nn.Linear(100,50)\n",
    "        self.l6 = nn.Linear(50,10)\n",
    "        self.softmax = nn.Linear(10,self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.l1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.l2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.l3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.l4(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.l5(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.l6(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder,soft, encoder_optimizer, decoder_optimizer,soft_optimizer, criterion,result, max_length=MAX_LENGTH):\n",
    "    batch_size = input_tensor.size(0)\n",
    "    input_length = input_tensor.size(1)\n",
    "    target_length = target_tensor.size(1)\n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    soft_optimizer.zero_grad()\n",
    "\n",
    "    # print(input_tensor.shape)\n",
    "    \n",
    "\n",
    "    # encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    encoder_outputs = torch.zeros([batch_size, max_length, encoder.hidden_size], device=device)\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[:,ei], encoder_hidden)\n",
    "        encoder_outputs[:,ei,:] = encoder_output[:, 0]\n",
    "\n",
    "    # decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_input = torch.zeros([batch_size,1], device=device, dtype=torch.long)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    soft_input = torch.zeros(batch_size, max_length, device=device)\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        decoder_output = decoder_output.view(batch_size,-1)\n",
    "        for i in range(batch_size):\n",
    "            soft_input[i,di] = decoder_output[i]\n",
    "\n",
    "        # loss += criterion(decoder_output, target_tensor[di])\n",
    "        decoder_input = target_tensor[:,di]  # Teacher forcing\n",
    "\n",
    "\n",
    "    soft_output=soft(soft_input)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        soft_one=soft_output[i].squeeze()\n",
    "        result_one = result[i].squeeze()\n",
    "        loss+=criterion(soft_one,result_one) \n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    soft_optimizer.step()\n",
    "\n",
    "    return loss.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = len(premise_vec)\n",
    "\n",
    "def trainIters(encoder, decoder,soft, n_iters, print_every=1000, plot_every=100, learning_rate=0.01, epoch_num=10, batch_size=64):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    soft.train()\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    soft_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    result = torch.zeros(data_length,device=device).long()\n",
    "    for i in range(data_length):\n",
    "        result[i]=training_labels[i]\n",
    "\n",
    "    batch_input = torch.zeros(batch_size,MAX_LENGTH,device=device).long()\n",
    "    batch_target = torch.zeros(batch_size,MAX_LENGTH,device=device).long()\n",
    "\n",
    "    count = 0\n",
    "    sum = 0\n",
    "\n",
    "    for i in range(epoch_num):\n",
    "\n",
    "        index = 0\n",
    "\n",
    "        while index + batch_size < n_iters:\n",
    "\n",
    "            for batch in range(batch_size):\n",
    "                input_tensor = premise_vec[index+batch]\n",
    "                target_tensor = hypothesis_vec[index+batch]\n",
    "                # print(input_tensor)\n",
    "                for iter in range(len(input_tensor)):\n",
    "                    batch_input[batch][iter] = input_tensor[iter]\n",
    "                for iter in range(len(target_tensor)):\n",
    "                    batch_target[batch][iter] = target_tensor[iter]\n",
    "\n",
    "\n",
    "            loss = train(batch_input, batch_target, encoder,\n",
    "                        decoder,soft, encoder_optimizer, decoder_optimizer,soft_optimizer, criterion,result[index:index+batch_size])\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            count += 1\n",
    "            sum += loss\n",
    "            \n",
    "\n",
    "            print(index,\" data: loss = \",sum/count)\n",
    "\n",
    "            index += batch_size\n",
    "\n",
    "\n",
    "    # showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and evaluate your model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  data: loss =  36.19694519042969\n",
      "32  data: loss =  35.62521743774414\n",
      "64  data: loss =  35.727823893229164\n",
      "96  data: loss =  35.761539459228516\n",
      "128  data: loss =  35.957678985595706\n",
      "160  data: loss =  35.906670888264976\n",
      "192  data: loss =  36.1416380746024\n",
      "224  data: loss =  36.0891809463501\n",
      "256  data: loss =  36.06988525390625\n",
      "288  data: loss =  36.00167007446289\n",
      "320  data: loss =  36.11697491732511\n",
      "352  data: loss =  36.10604985555013\n",
      "384  data: loss =  35.9520137493427\n",
      "416  data: loss =  35.911708286830354\n",
      "448  data: loss =  35.953006490071616\n",
      "480  data: loss =  35.83302068710327\n",
      "512  data: loss =  35.82648894366096\n",
      "544  data: loss =  35.7864793141683\n",
      "576  data: loss =  35.864562586734166\n",
      "608  data: loss =  35.87766437530517\n",
      "640  data: loss =  35.79988479614258\n",
      "672  data: loss =  35.84831914034757\n",
      "704  data: loss =  35.88642319389012\n",
      "736  data: loss =  35.90742556254069\n",
      "768  data: loss =  35.88663803100586\n",
      "800  data: loss =  35.89112868675819\n",
      "832  data: loss =  35.86531646163375\n",
      "864  data: loss =  35.830671719142366\n",
      "896  data: loss =  35.79902056989999\n",
      "928  data: loss =  35.802903747558595\n",
      "960  data: loss =  35.817883891444055\n",
      "992  data: loss =  35.82918179035187\n",
      "1024  data: loss =  35.85418724291252\n",
      "1056  data: loss =  35.883929645313934\n",
      "1088  data: loss =  35.86975272042411\n",
      "1120  data: loss =  35.89741028679742\n",
      "1152  data: loss =  35.86746927209803\n",
      "1184  data: loss =  35.90947171261436\n",
      "1216  data: loss =  35.86497076963767\n",
      "1248  data: loss =  35.832809925079346\n",
      "1280  data: loss =  35.81208624490878\n",
      "1312  data: loss =  35.76805750528971\n",
      "1344  data: loss =  35.749803587447765\n",
      "1376  data: loss =  35.72918137637052\n",
      "1408  data: loss =  35.75325715806749\n",
      "1440  data: loss =  35.77016855322796\n",
      "1472  data: loss =  35.784490707072806\n",
      "1504  data: loss =  35.80004668235779\n",
      "1536  data: loss =  35.802403274847535\n",
      "1568  data: loss =  35.798331069946286\n",
      "1600  data: loss =  35.79269558775659\n",
      "1632  data: loss =  35.8183997961191\n",
      "1664  data: loss =  35.80994350505325\n",
      "1696  data: loss =  35.859459700407804\n",
      "1728  data: loss =  35.876470808549364\n",
      "1760  data: loss =  35.900099413735525\n",
      "1792  data: loss =  35.907468226918006\n",
      "1824  data: loss =  35.892744393184266\n",
      "1856  data: loss =  35.893130415577\n",
      "1888  data: loss =  35.893795585632326\n",
      "1920  data: loss =  35.90857071172996\n",
      "1952  data: loss =  35.89052267997496\n",
      "1984  data: loss =  35.87388629005069\n",
      "2016  data: loss =  35.876735389232635\n",
      "2048  data: loss =  35.8692123413086\n",
      "2080  data: loss =  35.87204586375844\n",
      "2112  data: loss =  35.87295623323811\n",
      "2144  data: loss =  35.88858598821304\n",
      "2176  data: loss =  35.86858019621476\n",
      "2208  data: loss =  35.85492597307478\n",
      "2240  data: loss =  35.866185685278666\n",
      "2272  data: loss =  35.84732453028361\n",
      "2304  data: loss =  35.856692431724234\n",
      "2336  data: loss =  35.84155825022105\n",
      "2368  data: loss =  35.839963887532555\n",
      "2400  data: loss =  35.83933724855122\n",
      "2432  data: loss =  35.83781319159966\n",
      "2464  data: loss =  35.83023907588078\n",
      "2496  data: loss =  35.83488078057012\n",
      "2528  data: loss =  35.85282011032105\n",
      "2560  data: loss =  35.857936953320916\n",
      "2592  data: loss =  35.838258371120546\n",
      "2624  data: loss =  35.83452564836985\n",
      "2656  data: loss =  35.833394368489586\n",
      "2688  data: loss =  35.81552671544692\n",
      "2720  data: loss =  35.8003250388212\n",
      "2752  data: loss =  35.78466419789983\n",
      "2784  data: loss =  35.788549639961936\n",
      "2816  data: loss =  35.78780167826106\n",
      "2848  data: loss =  35.78863377041287\n",
      "2880  data: loss =  35.77746280209049\n",
      "2912  data: loss =  35.80018777432649\n",
      "2944  data: loss =  35.78856470251596\n",
      "2976  data: loss =  35.80282799741055\n",
      "3008  data: loss =  35.79123743960732\n",
      "3040  data: loss =  35.782819747924805\n",
      "3072  data: loss =  35.759886318875346\n",
      "3104  data: loss =  35.74980657927844\n",
      "3136  data: loss =  35.74081813927853\n",
      "3168  data: loss =  35.75470314025879\n",
      "3200  data: loss =  35.777021615812096\n",
      "3232  data: loss =  35.76527172911401\n",
      "3264  data: loss =  35.780563984102415\n",
      "3296  data: loss =  35.77881618646475\n",
      "3328  data: loss =  35.7796149844215\n",
      "3360  data: loss =  35.77840754670917\n",
      "3392  data: loss =  35.76916632251205\n",
      "3424  data: loss =  35.76009626741762\n",
      "3456  data: loss =  35.76894599144612\n",
      "3488  data: loss =  35.76563970392401\n",
      "3520  data: loss =  35.7573225004179\n",
      "3552  data: loss =  35.74978198323931\n",
      "3584  data: loss =  35.74003955537239\n",
      "3616  data: loss =  35.73108522515548\n",
      "3648  data: loss =  35.73161783633025\n",
      "3680  data: loss =  35.73911709621035\n",
      "3712  data: loss =  35.74303005903195\n",
      "3744  data: loss =  35.742851645259535\n",
      "3776  data: loss =  35.74888505054121\n",
      "3808  data: loss =  35.75100596745809\n",
      "3840  data: loss =  35.750329451127485\n",
      "3872  data: loss =  35.74447403579462\n",
      "3904  data: loss =  35.734994872798765\n",
      "3936  data: loss =  35.73872018629505\n",
      "3968  data: loss =  35.731127227783205\n",
      "4000  data: loss =  35.72574915204729\n",
      "4032  data: loss =  35.73624693502591\n",
      "4064  data: loss =  35.730912923812866\n",
      "4096  data: loss =  35.74284404192784\n",
      "4128  data: loss =  35.7535091987023\n",
      "4160  data: loss =  35.75582003411446\n",
      "4192  data: loss =  35.75556367816347\n",
      "4224  data: loss =  35.7497559454208\n",
      "4256  data: loss =  35.746004303889485\n",
      "4288  data: loss =  35.75585968582718\n",
      "4320  data: loss =  35.744745198418116\n",
      "4352  data: loss =  35.76127162292926\n",
      "4384  data: loss =  35.76442862248075\n",
      "4416  data: loss =  35.754504690924996\n",
      "4448  data: loss =  35.75716239384243\n",
      "4480  data: loss =  35.74830438059273\n",
      "4512  data: loss =  35.759516138426015\n",
      "4544  data: loss =  35.7607295963314\n",
      "4576  data: loss =  35.76278167300754\n",
      "4608  data: loss =  35.75279454198377\n",
      "4640  data: loss =  35.74655916919447\n",
      "4672  data: loss =  35.741365834969244\n",
      "4704  data: loss =  35.75074389174178\n",
      "4736  data: loss =  35.7532662769292\n",
      "4768  data: loss =  35.76068064371745\n",
      "4800  data: loss =  35.7590266095092\n",
      "4832  data: loss =  35.76318088330721\n",
      "4864  data: loss =  35.766361186706945\n",
      "4896  data: loss =  35.76950018746512\n",
      "4928  data: loss =  35.7713500238234\n",
      "4960  data: loss =  35.78005494826879\n",
      "4992  data: loss =  35.767247825671156\n",
      "5024  data: loss =  35.76440055460869\n",
      "5056  data: loss =  35.762474060058594\n",
      "5088  data: loss =  35.76046214103699\n",
      "5120  data: loss =  35.749734013717365\n",
      "5152  data: loss =  35.747173332873686\n",
      "5184  data: loss =  35.752738929233665\n",
      "5216  data: loss =  35.75501846685642\n",
      "5248  data: loss =  35.75641759236654\n",
      "5280  data: loss =  35.75091162072607\n",
      "5312  data: loss =  35.75273986633666\n",
      "5344  data: loss =  35.75454634711856\n",
      "5376  data: loss =  35.75518622765174\n",
      "5408  data: loss =  35.744746286728805\n",
      "5440  data: loss =  35.74389275891042\n",
      "5472  data: loss =  35.73906073459359\n",
      "5504  data: loss =  35.73347122545187\n",
      "5536  data: loss =  35.73643842236749\n",
      "5568  data: loss =  35.73102789742606\n",
      "5600  data: loss =  35.7370735948736\n",
      "5632  data: loss =  35.74156007928363\n",
      "5664  data: loss =  35.74026435680604\n",
      "5696  data: loss =  35.74026007625644\n",
      "5728  data: loss =  35.74064670138889\n",
      "5760  data: loss =  35.73500360309748\n",
      "5792  data: loss =  35.730872479113906\n",
      "5824  data: loss =  35.72745962090831\n",
      "5856  data: loss =  35.726760345956556\n",
      "5888  data: loss =  35.71798642132733\n",
      "5920  data: loss =  35.724533675819316\n",
      "5952  data: loss =  35.721603944339854\n",
      "5984  data: loss =  35.7173949302511\n",
      "6016  data: loss =  35.72384138965102\n",
      "6048  data: loss =  35.728460793746144\n",
      "6080  data: loss =  35.72805854038418\n",
      "6112  data: loss =  35.72912617524465\n",
      "6144  data: loss =  35.72735730106967\n",
      "6176  data: loss =  35.72941514634594\n",
      "6208  data: loss =  35.72937702276768\n",
      "6240  data: loss =  35.72969825900331\n",
      "6272  data: loss =  35.72858773633308\n",
      "6304  data: loss =  35.72313470551462\n",
      "6336  data: loss =  35.726488180495984\n",
      "6368  data: loss =  35.71907718658447\n",
      "6400  data: loss =  35.71944165585646\n",
      "6432  data: loss =  35.721805459201924\n",
      "6464  data: loss =  35.72882534835139\n",
      "6496  data: loss =  35.732068716310984\n",
      "6528  data: loss =  35.729702665747666\n",
      "6560  data: loss =  35.720527852623206\n",
      "6592  data: loss =  35.72478392964976\n",
      "6624  data: loss =  35.72477047259991\n",
      "6656  data: loss =  35.7223156650671\n",
      "6688  data: loss =  35.72683744884672\n",
      "6720  data: loss =  35.72239553080916\n",
      "6752  data: loss =  35.72654241885779\n",
      "6784  data: loss =  35.71677533001967\n",
      "6816  data: loss =  35.72025218856669\n",
      "6848  data: loss =  35.72525136193564\n",
      "6880  data: loss =  35.72499162179452\n",
      "6912  data: loss =  35.73121970040457\n",
      "6944  data: loss =  35.722220237101986\n",
      "6976  data: loss =  35.729287848625006\n",
      "7008  data: loss =  35.72653583179821\n",
      "7040  data: loss =  35.71863476507264\n",
      "7072  data: loss =  35.71175559791359\n",
      "7104  data: loss =  35.71393128467782\n",
      "7136  data: loss =  35.7127891268049\n",
      "7168  data: loss =  35.718224656846786\n",
      "7200  data: loss =  35.71497206561333\n",
      "7232  data: loss =  35.704618613625414\n",
      "7264  data: loss =  35.70114565732186\n",
      "7296  data: loss =  35.69831746530325\n",
      "7328  data: loss =  35.69429032698922\n",
      "7360  data: loss =  35.696999537480345\n",
      "7392  data: loss =  35.69392255256916\n",
      "7424  data: loss =  35.694042958926744\n",
      "7456  data: loss =  35.6892758393899\n",
      "7488  data: loss =  35.68058169750457\n",
      "7520  data: loss =  35.685900316400044\n",
      "7552  data: loss =  35.6840485359546\n",
      "7584  data: loss =  35.68879031333603\n",
      "7616  data: loss =  35.688413755664264\n",
      "7648  data: loss =  35.68635449409485\n",
      "7680  data: loss =  35.69044382245709\n",
      "7712  data: loss =  35.686430592182255\n",
      "7744  data: loss =  35.685201385874805\n",
      "7776  data: loss =  35.69277808705314\n",
      "7808  data: loss =  35.697564417002155\n",
      "7840  data: loss =  35.693587496997864\n",
      "7872  data: loss =  35.6909960078807\n",
      "7904  data: loss =  35.68977319040606\n",
      "7936  data: loss =  35.686087658127626\n",
      "7968  data: loss =  35.68573849487305\n",
      "8000  data: loss =  35.683710333835556\n",
      "8032  data: loss =  35.69000522674076\n",
      "8064  data: loss =  35.67977140826199\n",
      "8096  data: loss =  35.67972958181787\n",
      "8128  data: loss =  35.67203066956763\n",
      "8160  data: loss =  35.67641757428646\n",
      "8192  data: loss =  35.67522611506718\n",
      "8224  data: loss =  35.67513464402783\n",
      "8256  data: loss =  35.67687765879981\n",
      "8288  data: loss =  35.676780524620646\n",
      "8320  data: loss =  35.673583779755226\n",
      "8352  data: loss =  35.676319995909246\n",
      "8384  data: loss =  35.67268091644171\n",
      "8416  data: loss =  35.67206819129713\n",
      "8448  data: loss =  35.675509485208764\n",
      "8480  data: loss =  35.673435555364854\n",
      "8512  data: loss =  35.67032317543744\n",
      "8544  data: loss =  35.663492473203746\n",
      "8576  data: loss =  35.6589360999352\n",
      "8608  data: loss =  35.66216665197302\n",
      "8640  data: loss =  35.66011556928008\n",
      "8672  data: loss =  35.660601657979626\n",
      "8704  data: loss =  35.66179314637795\n",
      "8736  data: loss =  35.66175604214634\n",
      "8768  data: loss =  35.66075961026279\n",
      "8800  data: loss =  35.66729151684305\n",
      "8832  data: loss =  35.66336100884723\n",
      "8864  data: loss =  35.66211648296109\n",
      "8896  data: loss =  35.660628698205436\n",
      "8928  data: loss =  35.659214115142824\n",
      "8960  data: loss =  35.65849837713819\n",
      "8992  data: loss =  35.66065719279837\n",
      "9024  data: loss =  35.65801453337652\n",
      "9056  data: loss =  35.661089050937704\n",
      "9088  data: loss =  35.66840092173794\n",
      "9120  data: loss =  35.6704336713244\n",
      "9152  data: loss =  35.674597404559734\n",
      "9184  data: loss =  35.68105337354872\n",
      "9216  data: loss =  35.67419500911937\n",
      "9248  data: loss =  35.66762653219289\n",
      "9280  data: loss =  35.66642294552727\n",
      "9312  data: loss =  35.66637227306627\n",
      "9344  data: loss =  35.665421300373794\n",
      "9376  data: loss =  35.66567327538315\n",
      "9408  data: loss =  35.665446562686206\n",
      "9440  data: loss =  35.670154403995824\n",
      "9472  data: loss =  35.67192807181516\n",
      "9504  data: loss =  35.67008885121186\n",
      "9536  data: loss =  35.67702827326031\n",
      "9568  data: loss =  35.67653299967448\n",
      "9600  data: loss =  35.68363863922829\n",
      "9632  data: loss =  35.68044528582238\n",
      "9664  data: loss =  35.68098892866582\n",
      "9696  data: loss =  35.676262955916556\n",
      "9728  data: loss =  35.67508629970863\n",
      "9760  data: loss =  35.67322760937261\n",
      "9792  data: loss =  35.66547893312933\n",
      "9824  data: loss =  35.662635159182855\n",
      "9856  data: loss =  35.6593544352016\n",
      "9888  data: loss =  35.65762698265814\n",
      "9920  data: loss =  35.656702832777015\n",
      "9952  data: loss =  35.6540929720952\n",
      "9984  data: loss =  35.65796304282289\n",
      "10016  data: loss =  35.65514174540331\n",
      "10048  data: loss =  35.66065941462441\n",
      "10080  data: loss =  35.66363685945921\n",
      "10112  data: loss =  35.66110156086341\n",
      "10144  data: loss =  35.662565327290466\n",
      "10176  data: loss =  35.66550880838711\n",
      "10208  data: loss =  35.664201056957246\n",
      "10240  data: loss =  35.66164102286936\n",
      "10272  data: loss =  35.66062633443323\n",
      "10304  data: loss =  35.66522761247475\n",
      "10336  data: loss =  35.66295933429106\n",
      "10368  data: loss =  35.66709216778095\n",
      "10400  data: loss =  35.66807002670195\n",
      "10432  data: loss =  35.67092466208548\n",
      "10464  data: loss =  35.670704748572376\n",
      "10496  data: loss =  35.6714488670094\n",
      "10528  data: loss =  35.67122870936538\n",
      "10560  data: loss =  35.67706871608953\n",
      "10592  data: loss =  35.67603811011257\n",
      "10624  data: loss =  35.68166993974565\n",
      "10656  data: loss =  35.68121117460514\n",
      "10688  data: loss =  35.68012511979288\n",
      "10720  data: loss =  35.67988307135446\n",
      "10752  data: loss =  35.68120859072541\n",
      "10784  data: loss =  35.68096476899096\n",
      "10816  data: loss =  35.67511822410741\n",
      "10848  data: loss =  35.67644605075612\n",
      "10880  data: loss =  35.67621835166059\n",
      "10912  data: loss =  35.677329492847825\n",
      "10944  data: loss =  35.67586985551929\n",
      "10976  data: loss =  35.67891884959021\n",
      "11008  data: loss =  35.67787091904792\n",
      "11040  data: loss =  35.685014570379536\n",
      "11072  data: loss =  35.67640140764308\n",
      "11104  data: loss =  35.68158727404715\n",
      "11136  data: loss =  35.68341688576947\n",
      "11168  data: loss =  35.68257208687918\n",
      "11200  data: loss =  35.68674379875857\n",
      "11232  data: loss =  35.68304564736106\n",
      "11264  data: loss =  35.68335523956558\n",
      "11296  data: loss =  35.68783735286045\n",
      "11328  data: loss =  35.684712563098316\n",
      "11360  data: loss =  35.68387836284852\n",
      "11392  data: loss =  35.682112557547434\n",
      "11424  data: loss =  35.68468076823144\n",
      "11456  data: loss =  35.68385362757946\n",
      "11488  data: loss =  35.68508342107137\n",
      "11520  data: loss =  35.6833338539356\n",
      "11552  data: loss =  35.68621061124854\n",
      "11584  data: loss =  35.68538837065053\n",
      "11616  data: loss =  35.68621389158479\n",
      "11648  data: loss =  35.683757405738305\n",
      "11680  data: loss =  35.68217971676686\n",
      "11712  data: loss =  35.67792610771325\n",
      "11744  data: loss =  35.678237002828844\n",
      "11776  data: loss =  35.67964269539851\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\use\\Desktop\\prml\\failed_models\\encoder_decoder.ipynb Cell 39'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000038?line=2'>3</a>\u001b[0m attn_decoder1 \u001b[39m=\u001b[39m AttnDecoderRNN(hidden_size, Chinese\u001b[39m.\u001b[39mn_words, dropout_p\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000038?line=3'>4</a>\u001b[0m soft1 \u001b[39m=\u001b[39m Soft(MAX_LENGTH,\u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000038?line=5'>6</a>\u001b[0m trainIters(encoder1, attn_decoder1,soft1, \u001b[39m30000\u001b[39;49m, print_every\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, epoch_num\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\use\\Desktop\\prml\\failed_models\\encoder_decoder.ipynb Cell 36'\u001b[0m in \u001b[0;36mtrainIters\u001b[1;34m(encoder, decoder, soft, n_iters, print_every, plot_every, learning_rate, epoch_num, batch_size)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000035?line=40'>41</a>\u001b[0m     \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(target_tensor)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000035?line=41'>42</a>\u001b[0m         batch_target[batch][\u001b[39miter\u001b[39m] \u001b[39m=\u001b[39m target_tensor[\u001b[39miter\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000035?line=44'>45</a>\u001b[0m loss \u001b[39m=\u001b[39m train(batch_input, batch_target, encoder,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000035?line=45'>46</a>\u001b[0m             decoder,soft, encoder_optimizer, decoder_optimizer,soft_optimizer, criterion,result[index:index\u001b[39m+\u001b[39;49mbatch_size])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000035?line=46'>47</a>\u001b[0m print_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000035?line=47'>48</a>\u001b[0m plot_loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "\u001b[1;32mc:\\Users\\use\\Desktop\\prml\\failed_models\\encoder_decoder.ipynb Cell 35'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor, encoder, decoder, soft, encoder_optimizer, decoder_optimizer, soft_optimizer, criterion, result, max_length)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000034?line=46'>47</a>\u001b[0m     result_one \u001b[39m=\u001b[39m result[i]\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000034?line=47'>48</a>\u001b[0m     loss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mcriterion(soft_one,result_one) \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000034?line=49'>50</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000034?line=51'>52</a>\u001b[0m encoder_optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/use/Desktop/prml/failed_models/encoder_decoder.ipynb#ch0000034?line=52'>53</a>\u001b[0m decoder_optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\use\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\use\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/use/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 512\n",
    "encoder1 = EncoderRNN(Chinese.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, Chinese.n_words, dropout_p=0.1).to(device)\n",
    "soft1 = Soft(MAX_LENGTH,3).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1,soft1, 30000, print_every=10, learning_rate=0.01, epoch_num=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Attention Visualization (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the attention matrix in your model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Attack (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attack your model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down your conclusion here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] OCNLI: Original Chinese Natural Language Inference, arxiv: https://arxiv.org/abs/2010.05444"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd25d7946b0a4a98bcb45dc856450efaeb842b45623c7c1e964456c6d8aebe43"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
